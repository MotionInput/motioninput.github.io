# Setting Up
- Expected to be run on Python 3.9 + Windows
- Make sure you have installed all the libraries in the requirements.txt
- As we donâ€™t yet have the App layer and the app-specific main.py, we are using the [test files](https://motioninput.github.io/getting-started.html#examples) to run the system, so either use one of them or create your own as needed.

# Architecture
![Diagram](./MIv3.PNG)

So a quick overview of how the the system works. It can be oberved in 2 parts: the setup and the frame by frame processing.

## setup
- Firstly, information for gestures and events are loaded from the database (eventually)
- The event mapper class is used to initialise the required event classes and add them to the model
- Based on the added events the needed gestures and modules are automatically added to the model

## frame by frame
- The opencv image is retrieved from the camera class.
- Process the frame in the Model in following steps:
    - Update the modules:
        - Use the modules landmark detector (ML library) to retrieve the RawData (aka the coordinates of all landmarks) from the frame.
        - Update all position trackers with the RawData, which results in a set of primitives that had changed since the last frame.
        - Update all the gesture factories that use the changed primitives, which may create new active Gestures.
    - If the module created any Gesture instances, they are added to the model, which may lead to (de)activation of some gesture events.
    - Update all the active gestures, which may result in deactivation of some of them, and consequently (de)activation of some gesture events.
    - Run all active gesture events, which may result in the trigger functions in the events being called.

# Examples
We are aiming to soon have just a main.py file and some config files for testing/using the system with easily configurable functionality.

However, as we are not quite there yet currently, the repo contains 4 files that are being used to test the system:
1. hand_test.py for testing the hand module (configured for a lefthanded user)
2. touchpoint_test.py to test the touchpoin feature (currently only recognizes a single tap)
3. exercise_test.py
4. extremity_trigger_test.py
Note: Currently, for the extremity triggers in the body module, hardcoded calibration information is located in the LoadConfig file. In particular, the coordinates of the extremity triggers are set manually.


# Notes
- Please do keep in mind that this architecture was done on a tight schedule by a smol 2nd year, so I am sure there are some parts of it that were not implemented in the most efficient manner. So if you have an idea of how to improve something let me know.
- If there is some functionality missing from the core that you need, feel free to let me know. If it makes sense I will add it or make the needed changes.
- If there are any primitives/gestures/events/event_handlers that you are missing feel free to add them in yourself (as in please do we really could use some help here:))

-xoxo Carmen

## Adding Features
### Adding GestureEvents
Create a new class extending the [GestureEvent](https://motioninput.github.io/apidocs/scripts.gesture_events.html) class from the [core](https://motioninput.github.io/apidocs/scripts.core.html#) module (many examples are available in the gesture_events folder).
You can check the currently available gestures in the GestureLoader class (script.gesture_loader.py) and in case the gestures you need are not available feel free to add a new [Gesture](https://motioninput.github.io/getting-started.html#adding-gestures).
(Just a note that you are allowed to use gestures from different modules in the seme event)
Once you have added the event class into the gesture_events folder, you need to add it to the folders \_\_init\_\_.py file in the same way the previous events were added, in order for the EventMapper to have access to it. Now if you want to actually add the event into your Model and use it first you need to add it into the event_mapper.py as the other events have been added (this is where you map the events triggers to actual functions from the gesture event handlers and if the handlers you require are not available to you feel free to [add a new event handler](https://motioninput.github.io/getting-started.html#adding-event-handlers)).
Now you are all set and should be able to use the gesture event after adding it to the Model in your test file.

### Adding Gestures
Adding new [Gestures](https://motioninput.github.io/apidocs/scripts.core.html#scripts.core.gesture.Gesture) is as easy as adding one line to the script.gesture_loader.py file, with just the name of the gesture and a set of all the primitives it uses. (again plenty of examples already available). Note that the name of the gesture should not overlap with the name of any other gesture, even in other modules.
In case the primitives you need are not available feel free to add a new [primitive](https://motioninput.github.io/getting-started.html#adding-primitives).

### Adding Primitives
Now adding primitives is a bit trickier and definitely should not be done too often, as unlike Gestures and GestureEvents the primitives affect the efficiency of processing each frame, as for every frame we calculate the states of all the primitives.
Adding primitives is done in the specific modules [Position](https://motioninput.github.io/apidocs/scripts.core.html#scripts.core.position.Position) classes (so currently in the HandPositio, BodyPosition and ExercisePosition classes)

### Adding event handlers
Event handlers (classes that contain all the functions that are called by GestureEvents and are responsible for actually controlling the users computer e.g. moving the mouse or pressing keys) are stored in the gesture_event_handlers folder. If you have added any new classes or new functions to already exicsting handler classes, please first add them to the \_\_init\_\_.py file in the gesture_event_handlers folder in the same manner as the previous examples, in order for the EventMapper class to be able to use the new functionality. After this you can now use your handler by mapping GestureEvents to it in the EventMapper class.
